{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XqU5Epb_Q9Ej"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import json\n",
        "from scipy.optimize import minimize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QpXP4JTlQ9El"
      },
      "outputs": [],
      "source": [
        "with open('result.json', 'r', encoding='utf-8') as f:\n",
        "    raw_data = json.load(f)\n",
        "\n",
        "data = {}\n",
        "scale = 10 # q-value가 너무 크게 변해 alpha가 0에 가까워지는 현상 방지\n",
        "\n",
        "for subj, lists in raw_data.items():\n",
        "    choices, gains, losses, rewards = lists\n",
        "    choices = (np.array(choices, dtype=int) - 1) # 1~4 -> 0~3\n",
        "    gains = np.array(gains, dtype=float) / scale\n",
        "    losses = np.array(losses, dtype=float) / scale\n",
        "    rewards = np.array(rewards, dtype=float) / scale\n",
        "\n",
        "    data[int(subj)] = {\n",
        "        \"choices\": choices,\n",
        "        \"gains\": gains,\n",
        "        \"losses\": losses,\n",
        "        \"rewards\": rewards,\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88_o3L9Xuip4"
      },
      "outputs": [],
      "source": [
        "def neg_log_likelihood(params, trials, vs = False):\n",
        "  if vs: # vs: valence-specific Q-learning\n",
        "    a_p, a_m, b, w = params # alpha_plus, alpha_minus, beta, weight\n",
        "    Q_pos = np.zeros(4)\n",
        "    Q_neg = np.zeros(4)\n",
        "  else:\n",
        "    a, b = params # alpha, beta\n",
        "    Q = np.zeros(4) # initialize Q-values for 4 decks (A, B, C, D)\n",
        "\n",
        "  nll = 0\n",
        "\n",
        "  for t in trials:\n",
        "    if vs:\n",
        "      action, gain, loss = t\n",
        "      Q_comb = w * Q_pos - (1 - w) * Q_neg\n",
        "\n",
        "      logits = b * Q_comb\n",
        "      logits -= np.max(logits) # overflow 방지\n",
        "      probs = np.exp(logits)\n",
        "      probs /= np.sum(probs)\n",
        "      nll -= np.log(probs[action] + 1e-12)\n",
        "\n",
        "      Q_pos[action] += a_p * (gain - Q_pos[action])\n",
        "      if loss != 0:\n",
        "        Q_neg[action] += a_m * (abs(loss) - Q_neg[action])\n",
        "\n",
        "    else:\n",
        "      action, reward = t\n",
        "\n",
        "      logits = b * Q\n",
        "      logits -= np.max(logits)\n",
        "      probs = np.exp(logits)\n",
        "      probs /= np.sum(probs)\n",
        "      nll -= np.log(probs[action] + 1e-12)\n",
        "\n",
        "      Q[action] += a * (reward - Q[action])\n",
        "\n",
        "  return nll"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xneTESFXs7dt",
        "outputId": "221b1e5b-acb6-4200-c9d0-ea3a7fe3ffdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subject 1: nll_q=92.36, nll_vs=75.81\n",
            "  Q-learning params:  α=0.0000847527, β=259.7964685233\n",
            "  VSQ-learning params: α+=0.0000630007, α-=0.0004930602, β=738.1551533072, w=0.958\n",
            "\n",
            "Subject 2: nll_q=54.41, nll_vs=64.48\n",
            "  Q-learning params:  α=0.0867112009, β=0.8064830945\n",
            "  VSQ-learning params: α+=0.0010256615, α-=0.0001558659, β=342.5718623652, w=0.048\n",
            "\n",
            "Subject 3: nll_q=10.26, nll_vs=12.90\n",
            "  Q-learning params:  α=0.0002352935, β=663.4377877746\n",
            "  VSQ-learning params: α+=0.0002065520, α-=0.0000000000, β=602.6192697122, w=1.000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "params_sub = [] ## 각 참가자의 추정 파라미터를 저장할 리스트\n",
        "init_q = [0.0001, 1.0] # q learning의 초기 alpha, beta\n",
        "bounds_q = [(0, 1), (0, 1000)] ## alpha, beta bound\n",
        "init_vs = [0.0001, 0.0001, 1.0, 0.5] # VSQ learning의 초기 a_p, a_m, b, w, weight\n",
        "bounds_vs = [(0, 1), (0, 1), (0, 1000), (0, 1)] ## bound\n",
        "\n",
        "## 파라미터 추정하기 (전체 subject)\n",
        "for subj, d in data.items():\n",
        "    ## Q leanring 학습 데이터 준비\n",
        "    trials_q  = list(zip(d[\"choices\"], d[\"rewards\"]))\n",
        "\n",
        "    ## VSQ 학습 데이터 준비\n",
        "    trials_vs = list(zip(d[\"choices\"], d[\"gains\"], d[\"losses\"]))\n",
        "\n",
        "    params_q = minimize(\n",
        "        neg_log_likelihood, ## 최적화 대상 함수\n",
        "        x0 = init_q, ## 초기값\n",
        "        args = (trials_q, False), ## 인자\n",
        "        bounds = bounds_q ## 파라미터 제한 범위\n",
        "    )\n",
        "\n",
        "    params_vs = minimize(\n",
        "        neg_log_likelihood, ## 최적화 대상 함수\n",
        "        x0 = init_vs, ## 초기값\n",
        "        args = (trials_vs, True), #인자\n",
        "        bounds = bounds_vs #파라미터 제한 범위\n",
        "    )\n",
        "    ## 결과 저장\n",
        "    params_sub.append({\n",
        "        \"subj\": subj,\n",
        "        \"q_alpha\": params_q.x[0],\n",
        "        \"q_beta\": params_q.x[1],\n",
        "        \"vs_alpha_plus\": params_vs.x[0],\n",
        "        \"vs_alpha_minus\": params_vs.x[1],\n",
        "        \"vs_beta\": params_vs.x[2],\n",
        "        \"vs_w\": params_vs.x[3],\n",
        "        \"nll_q\": params_q.fun,\n",
        "        \"nll_vs\": params_vs.fun\n",
        "    })\n",
        "    print(f\"Subject {subj}: nll_q={params_q.fun:.2f}, nll_vs={params_vs.fun:.2f}\")\n",
        "    print(f\"  Q-learning params:  α={params_q.x[0]:.10f}, β={params_q.x[1]:.10f}\")\n",
        "    print(f\"  VSQ-learning params: α+={params_vs.x[0]:.10f}, α-={params_vs.x[1]:.10f}, β={params_vs.x[2]:.10f}, w={params_vs.x[3]:.3f}\\n\")\n",
        "\n",
        "with open(\"params_ours.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "  json.dump(params_sub, f, ensure_ascii=False, indent=4)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}